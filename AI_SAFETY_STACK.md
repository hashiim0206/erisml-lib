# The EFM AI Safety Stack

> *From Metaphysics to Deployment â€” A Unified Architecture for Verifiable AI Alignment*

---

## Overview

```
â•”â•â•â•â•â•â•â•¦â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘  L7  â•‘  The Geometry of Good å¡ç¿å¤±é©¬                           [APPLICATION]  â•‘
â•‘      â•‘  Real-world deployment under uncertainty                               â•‘
â• â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘      â•‘  â”„â”„â”„ Layers 5-6: Future Work â”„â”„â”„                                        â•‘
â•‘      â•‘  Multi-agent coordination, transform representation                    â•‘
â• â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  L4  â•‘  Philosophy Engineering                                   [TRANSPORT]  â•‘
â•‘      â•‘  The methodological turn â€” ethics becomes testable                     â•‘
â• â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  L3  â•‘  GUASS (Grand Unified AI Safety Stack)                     [NETWORK]   â•‘
â•‘      â•‘  The integration layer â€” everything connects here                      â•‘
â• â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  L2  â•‘  Noether Ethics                                           [DATA LINK]  â•‘
â•‘      â•‘  Symmetries â†’ conservation laws for ethics                             â•‘
â• â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  L1  â•‘  Quantum Normative Dynamics                               [PHYSICAL]   â•‘
â•‘      â•‘  Superposition of ethical states until decision                        â•‘
â• â•â•â•â•â•â•â•¬â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  L0  â•‘  A Pragmatist Rebuttal                                   [FOUNDATION]  â•‘
â•‘      â•‘  Answering "why bother?" before building                               â•‘
â•šâ•â•â•â•â•â•â•©â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```

---

## The Core Insight

> *"For 2,500 years, ethical claims have been unfalsifiable. This framework changes the question â€” from 'Is this action right?' to 'Is this system consistent?'"*

### The Bond Index

```
        Bd = D_op / Ï„

   Observed Defect Ã· Human-Calibrated Threshold
```

| Bd Range | Rating | Decision |
|----------|--------|----------|
| < 0.01   | **Negligible** | âœ… Deploy |
| 0.01 â€“ 0.1 | **Low** | âœ… Deploy with monitoring |
| 0.1 â€“ 1.0 | **Moderate** | âš ï¸ Remediate first |
| 1 â€“ 10 | **High** | ğŸ›‘ Do not deploy |
| > 10 | **Severe** | ğŸ”´ Fundamental redesign |

---

## Layer Descriptions

### L0 â€” A Pragmatist Rebuttal `[FOUNDATION]`

**The foundation.** Before building any framework, we must answer the skeptic: "Why bother with formal ethics for AI at all?"

This layer grounds the entire stack in *practical necessity*, not metaphysical certainty. We don't need to prove ethics is "real" â€” we need to show that systems without coherence verification fail in predictable, catastrophic ways.

**Key insight:** The argument isn't philosophical â€” it's engineering risk management.

---

### L1 â€” Quantum Normative Dynamics `[PHYSICAL]`

**The uncertainty layer.** Ethical states exist in superposition until "measured" by an actual decision. Uncertainty isn't a bug to be eliminated â€” it's a fundamental feature of normative reasoning.

This layer acknowledges that:
- Multiple ethical framings can coexist
- Commitment to one framing collapses others
- The act of deciding is itself morally significant

**Key insight:** Don't pretend certainty you don't have.

---

### L2 â€” Noether Ethics `[DATA LINK]`

**The symmetry layer.** Emmy Noether proved that every symmetry in physics corresponds to a conservation law. We apply the same principle to ethics:

| Physics | Ethics |
|---------|--------|
| Spatial symmetry â†’ Conservation of momentum | Representational invariance â†’ Conserved moral properties |
| Time symmetry â†’ Conservation of energy | Consistent judgment across equivalent descriptions |

The **Bond Index detects broken symmetries** â€” cases where equivalent inputs produce inequivalent outputs.

**Key insight:** If you declare an invariance, we can test it.

---

### L3 â€” GUASS `[NETWORK]`

**The integration layer.** The Grand Unified AI Safety Stack is where all components connect:

- **ErisML** â€” Formal language for agents, environments, norms
- **DEME** â€” Democratically Governed Ethics Modules (9 dimensions)
- **Bond Index** â€” Quantitative coherence verification
- **MCP Integration** â€” Works with any MCP-compatible agent
- **BIP Artifacts** â€” Machine-checkable audit trails

**Key insight:** The stack is modular. Use what you need.

---

### L4 â€” Philosophy Engineering `[TRANSPORT]`

**The methodological layer.** This is where philosophy becomes engineering:

```
Traditional Philosophy:    Claim â†’ Argue â†’ Disagree â†’ Repeat
Philosophy Engineering:    Claim â†’ Predict â†’ Test â†’ Witness â†’ Debug
```

We cannot test whether an ethical theory is *true*. But we **can** test whether an ethical judgment system is:

| Property | Test |
|----------|------|
| **Consistent** | Same judgment for equivalent inputs |
| **Non-gameable** | Cannot be exploited via redescription |
| **Accountable** | Differences traceable to specific factors |
| **Non-trivial** | Actually distinguishes between situations |

**Key insight:** Falsifiability applies to systems, not theories.

---

### L5-L6 â€” Future Work `[SESSION / PRESENTATION]`

These layers are intentionally left for future development:

- **L5 (Session):** Multi-agent coordination protocols, governance handshakes
- **L6 (Presentation):** Transform suite standardization, G_declared representation formats

**Contributions welcome.**

---

### L7 â€” The Geometry of Good å¡ç¿å¤±é©¬ `[APPLICATION]`

**The application layer.** Real-world deployment under irreducible uncertainty.

å¡ç¿å¤±é©¬ (SÄi WÄ“ng ShÄ« MÇ) â€” "The old man lost his horse." A Chinese parable about the entanglement of fortune and misfortune. You can't know which is which until much later.

This layer handles:
- Deployment decisions with incomplete information
- Monitoring and feedback loops
- Graceful degradation when coherence weakens
- The acknowledgment that *we might be wrong*

**Key insight:** Deploy humbly. Monitor continuously. Update honestly.

---

## OSI â†” EFM Analogy

| OSI Layer | OSI Function | EFM Layer | EFM Function |
|-----------|--------------|-----------|--------------|
| 7 - Application | User interface | Geometry of Good | Real-world decisions |
| 6 - Presentation | Data formatting | *(Future)* | Transform representation |
| 5 - Session | Connection management | *(Future)* | Multi-agent coordination |
| 4 - Transport | Reliable delivery | Philosophy Engineering | Reliable verification |
| 3 - Network | Routing | GUASS | Integration & routing |
| 2 - Data Link | Error detection | Noether Ethics | Symmetry violation detection |
| 1 - Physical | Raw signal | Quantum Normative | Raw ethical states |
| 0 - *(below OSI)* | â€” | Pragmatist Rebuttal | Grounding axioms |

---

## Key Concepts

### G_declared
The transform group defining "what shouldn't change the answer." You declare which transformations should preserve the ethical judgment, and the Bond Index tests whether they actually do.

### Witnesses
When invariance fails, you don't just get a number â€” you get a *minimal counterexample*. A specific input and transform pair that demonstrates the inconsistency. Witnesses enable debugging.

### Three Defect Types

| Symbol | Name | What It Measures |
|:------:|------|------------------|
| Î© | Commutator | Does transform order matter? (Aâˆ˜B vs Bâˆ˜A) |
| Î¼ | Mixed | Same transform, different results in different contexts? |
| Ï€â‚ƒ | Permutation | Three-way composition chain sensitivity? |

### DEME Dimensions
The 9 ethical dimensions in Democratically Governed Ethics Modules:

1. Consequences/Welfare
2. Rights/Duties
3. Justice/Fairness
4. Autonomy/Agency
5. Privacy/Data
6. Societal/Environmental
7. Virtue/Care
8. Procedural Legitimacy
9. Epistemic Status

---

## Why This Architecture?

| Principle | Implementation |
|-----------|----------------|
| **Bottom-up** | Start with pragmatic defense, not metaphysical claims |
| **Physics-inspired** | Symmetry â†’ conservation (Noether). Uncertainty â†’ superposition (QM). |
| **Falsifiable** | Every layer produces testable predictions |
| **Actionable** | Terminates in a deployment decision, not a paper |

---

## Data Flow

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Pragmatic    â”‚ â”€â”€> â”‚    Quantum     â”‚ â”€â”€> â”‚    Symmetry    â”‚ â”€â”€> â”‚    Unified     â”‚
â”‚    Ground      â”‚     â”‚  Uncertainty   â”‚     â”‚   Principles   â”‚     â”‚     Stack      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                             â”‚
                                                                             v
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚                      Testable Claims                           â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                             â”‚
                                                                             v
                                                                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                                â”‚  DEPLOY / DON'T    â”‚
                                                                â”‚      DEPLOY        â”‚
                                                                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## Quick Start

```bash
# Clone and install
git clone https://github.com/ahb-sjsu/erisml-lib.git
cd erisml-lib
pip install -e .

# Run Bond invariance demo
python -m erisml.examples.bond_invariance_demo

# Run DEME triage demo
python -m erisml.examples.triage_ethics_demo

# Run full calibration suite
python -m erisml.examples.bond_index_calibration_deme_fuzzing
```

---

## Related Documents

| Document | Description |
|----------|-------------|
| [README.md](README.md) | Full project documentation |
| [DISCUSSIONS_WELCOME.md](DISCUSSIONS_WELCOME.md) | Community onboarding |
| [CATEGORICAL_FRAMEWORK.md](docs/CATEGORICAL_FRAMEWORK.md) | IEEE TAI paper |
| [GUASS_SAI.md](GUASS_SAI.md) | Grand Unified AI Safety Stack v12.0 |
| [bond_invariance_principle.md](bond_invariance_principle.md) | Core falsifiability mechanism |

---

## Contributing

We need contributors across all layers:

- **L0-L1:** Philosophers, physicists, foundations researchers
- **L2:** Mathematicians (category theory, symmetry groups)
- **L3:** ML engineers, systems architects
- **L4:** Safety researchers, red-teamers
- **L7:** Domain experts, deployment practitioners

See [DISCUSSIONS_WELCOME.md](DISCUSSIONS_WELCOME.md) to get started.

---

<p align="center">
<i>"The Bond Index is the deliverable. Everything else is infrastructure."</i>
</p>

<p align="center">
<b>Ethical Finite Machines</b><br>
<i>Ordo ex ChÄÅnÄ; Ethos ex MÄchinÄ</i><br>
Order from Chaos; Ethics from Machines
</p>

---

<p align="center">
<a href="https://github.com/ahb-sjsu/erisml-lib">GitHub</a> â€¢
<a href="https://ethicalfinitemachines.com">Website</a> â€¢
<a href="mailto:andrew.bond@sjsu.edu">Contact</a>
</p>
