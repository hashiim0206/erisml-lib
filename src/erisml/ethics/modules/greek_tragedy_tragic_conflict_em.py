"""
greek_tragedy_tragic_conflict_em.py

A new "Greek Tragedy" Ethical Module (EM) that flags *tragic dilemma / moral remainder*
situations: cases where actions are simultaneously pulled by competing prima facie
reasons (urgency vs procedure, benefit vs coercion, privacy vs accountability, etc.).

This EM is *metaethically neutral*: it does NOT claim which moral theory is true.
It only detects "knife-edge" / conflict-heavy contexts and recommends escalation
or procedure-first options when the conflict index is high.

Integration options:
  A) Place this file under: src/erisml/ethics/modules/greek_tragedy_tragic_conflict_em.py
     and ensure it gets imported by your module registry (e.g., modules/__init__.py).

  B) Or, import it in your demo script and add `TragicConflictEM()` to the EM set.

The class is written defensively to survive minor API changes:
  - it constructs EthicalJudgement using signature reflection,
  - and registers itself via register_em() if available, else via EM_REGISTRY.

Author: generated by ChatGPT for ErisML demos
"""

from __future__ import annotations

import inspect
from typing import Any, Dict, List


# --- Imports with fallbacks (your erisml package already exports these in demos) ---
try:
    from erisml.ethics import EthicalFacts, EthicalJudgement
except Exception:  # pragma: no cover
    from erisml.ethics.facts import EthicalFacts  # type: ignore
    from erisml.ethics.judgement import EthicalJudgement  # type: ignore


def _coerce_verdict(verdict_str: str) -> Any:
    """
    Return the appropriate verdict object. In most installs, verdicts are plain strings.
    If your codebase uses an Enum type, we try to map into it.
    """
    # Most common: just a string
    try:
        # If verdict already works as-is, keep it.
        return verdict_str
    except Exception:  # pragma: no cover
        pass

    # Optional enum mapping (only if you use an enum in your build)
    try:  # pragma: no cover
        from erisml.ethics.judgement import Verdict  # type: ignore

        key = verdict_str.upper()
        if hasattr(Verdict, key):
            return getattr(Verdict, key)
        # sometimes enum constructor accepts the string value
        return Verdict(verdict_str)
    except Exception:
        return verdict_str


def _make_judgement(
    em_name: str,
    verdict: str,
    score: float,
    reasons: List[str],
    metadata: Dict[str, Any],
    option_id: str | None = None,
) -> EthicalJudgement:
    """
    Construct EthicalJudgement robustly via signature introspection.
    """
    verdict_obj = _coerce_verdict(verdict)
    score = float(max(0.0, min(1.0, score)))

    sig = inspect.signature(EthicalJudgement)
    kwargs: Dict[str, Any] = {}

    # Common field names observed in your demos
    if "em_name" in sig.parameters:
        kwargs["em_name"] = em_name
    if "em_id" in sig.parameters:
        kwargs["em_id"] = em_name
    # Attach option_id if the judgement schema supports it (aggregation validates this).
    if option_id is not None:
        if "option_id" in sig.parameters:
            kwargs["option_id"] = option_id
        elif "opt_id" in sig.parameters:  # alternate naming
            kwargs["opt_id"] = option_id
    if "verdict" in sig.parameters:
        kwargs["verdict"] = verdict_obj
    if "normative_score" in sig.parameters:
        kwargs["normative_score"] = score
    if "score" in sig.parameters and "normative_score" not in kwargs:
        kwargs["score"] = score
    if "reasons" in sig.parameters:
        kwargs["reasons"] = reasons
    if "metadata" in sig.parameters:
        kwargs["metadata"] = metadata

    # Provide any required-but-unfilled params with safe defaults if possible
    for name, param in sig.parameters.items():
        if name in kwargs:
            continue
        if param.default is not inspect._empty:
            continue
        # Required parameter with no default: fill with None
        kwargs[name] = None

    return EthicalJudgement(**kwargs)  # type: ignore[arg-type]


def _get(obj: Any, path: str, default: Any = None) -> Any:
    """
    Safe nested attribute getter: _get(facts, "consequences.urgency", 0.0)
    """
    cur = obj
    for part in path.split("."):
        if cur is None:
            return default
        if hasattr(cur, part):
            cur = getattr(cur, part)
        else:
            return default
    return cur if cur is not None else default


def _bool(obj: Any) -> bool:
    return bool(obj is True)


def _clip(text: str, n: int = 120) -> str:
    text = " ".join((text or "").split())
    return text if len(text) <= n else text[: n - 1] + "…"


# ---------------------------------------------------------------------------
# The EM
# ---------------------------------------------------------------------------


class TragicConflictEM:
    """
    TragicConflictEM detects "tragic structure": options that are attractive under one
    domain but costly under another in a way that tends to generate moral remainder.

    It does NOT hard-veto (leave that to Rights/Geneva). Instead, it:
      - computes a conflict index in [0,1],
      - penalizes the score when the index is high,
      - recommends escalation / procedure-first behavior when the index is high.

    You can use it as a stand-alone explanatory EM alongside your existing stack.
    """

    em_name: str = "tragic_conflict"
    em_id: str = "tragic_conflict"

    def judge(self, facts: EthicalFacts) -> EthicalJudgement:
        # Pull key coordinates (with safe defaults)
        urgency = float(_get(facts, "consequences.urgency", 0.0) or 0.0)
        benefit = float(_get(facts, "consequences.expected_benefit", 0.0) or 0.0)
        harm = float(_get(facts, "consequences.expected_harm", 0.0) or 0.0)

        followed_proc = _bool(
            _get(facts, "procedural_and_legitimacy.followed_approved_procedure", True)
        )
        contestation = _bool(
            _get(facts, "procedural_and_legitimacy.contestation_available", True)
        )
        consulted = _bool(
            _get(facts, "procedural_and_legitimacy.stakeholders_consulted", True)
        )
        explainable = _bool(
            _get(
                facts, "procedural_and_legitimacy.decision_explainable_to_public", True
            )
        )

        coercion = _bool(
            _get(facts, "autonomy_and_agency.coercion_or_undue_influence", False)
        )
        has_choice = _bool(
            _get(facts, "autonomy_and_agency.has_meaningful_choice", True)
        )

        privacy_inv = float(
            _get(facts, "privacy_and_data.privacy_invasion_level", 0.0) or 0.0
        )
        secondary_use = _bool(
            _get(facts, "privacy_and_data.secondary_use_without_consent", False)
        )

        power_imb = _bool(
            _get(facts, "justice_and_fairness.exacerbates_power_imbalance", False)
        )
        exploits = _bool(
            _get(facts, "justice_and_fairness.exploits_vulnerable_population", False)
        )

        violates_rights = _bool(_get(facts, "rights_and_duties.violates_rights", False))
        violates_rule = _bool(
            _get(facts, "rights_and_duties.violates_explicit_rule", False)
        )
        role_duty_conflict = _bool(
            _get(facts, "rights_and_duties.role_duty_conflict", False)
        )

        uncertainty = float(
            _get(facts, "epistemic_status.uncertainty_level", 0.0) or 0.0
        )
        evidence_quality = str(
            _get(facts, "epistemic_status.evidence_quality", "unknown") or "unknown"
        )

        triggers: List[str] = []
        conflict = 0.0

        # 1) Urgency vs procedure (classic tragedy: action needed, but procedure missing)
        if urgency >= 0.75 and (not followed_proc or not contestation):
            conflict += 0.25
            triggers.append("high_urgency_vs_missing_procedure")

        # 2) Benefit vs autonomy (ends/means tension)
        if benefit >= 0.65 and (coercion or not has_choice):
            conflict += 0.30
            triggers.append("high_benefit_vs_coercion")

        # 3) Accountability vs privacy (Hippolytus-style: evidence exists but disclosure harms)
        if privacy_inv >= 0.80 and (not explainable or secondary_use):
            conflict += 0.20
            triggers.append("severe_privacy_vs_accountability")

        # 4) Power imbalance / exploitation (Ajax-style honor politics)
        if power_imb or exploits:
            conflict += 0.20
            triggers.append("power_imbalance_or_exploitation")

        # 5) Explicit duty conflict / role conflict
        if role_duty_conflict:
            conflict += 0.20
            triggers.append("role_duty_conflict")

        # 6) Rights/rules violations are "tragic" only in the sense of high tension:
        #    we don't veto here, but we mark the conflict very high (usually means "avoid + escalate").
        if violates_rights or violates_rule:
            conflict += 0.35
            triggers.append("rights_or_rule_violation_present")

        # 7) Epistemic amplification: tragedy often emerges from ignorance (Oedipus)
        if uncertainty >= 0.60 or evidence_quality.lower() in {"low", "weak"}:
            conflict += 0.15
            triggers.append("high_epistemic_uncertainty")

        conflict = max(0.0, min(1.0, conflict))

        # Convert to a score: start from a "cautious optimistic" baseline,
        # then subtract a penalty, and add a small term for low harm.
        score = 0.80 - 0.70 * conflict + 0.10 * (1.0 - harm)
        score = max(0.0, min(1.0, score))

        # Verdict mapping (never forbid here)
        if conflict >= 0.80:
            verdict = "avoid"
        elif conflict >= 0.55:
            verdict = "neutral"
        else:
            verdict = "prefer" if score < 0.90 else "strongly_prefer"

        recommend_escalation = conflict >= 0.55

        reasons: List[str] = []
        reasons.append(
            "Tragic conflict check: flags choices likely to produce moral remainder "
            "(competing prima facie reasons across domains)."
        )
        reasons.append(
            f"Tragic conflict index={conflict:.2f} (higher means more tension across domains)."
        )
        if triggers:
            reasons.append("Trigger(s): " + ", ".join(triggers) + ".")
        if recommend_escalation:
            reasons.append(
                "Recommendation: prefer procedure-first options, seek consent/appeal, or escalate to governance review."
            )

        # Include boolean bullets so your provenance printers can attach trace entries if desired.
        reasons.append(f"• tragic_conflict_high = {str(conflict >= 0.55)}")

        metadata = {
            "tragic_conflict_index": conflict,
            "triggers": triggers,
            "recommend_escalation": recommend_escalation,
            "stakeholders_consulted": consulted,
        }

        opt_id = _get(facts, "option_id", None)
        return _make_judgement(
            self.em_name, verdict, score, reasons, metadata, option_id=opt_id
        )


# ---------------------------------------------------------------------------
# Optional registration with your EM registry
# ---------------------------------------------------------------------------


def _register() -> None:
    try:
        from erisml.ethics.modules import register_em  # type: ignore

        register_em("tragic_conflict")(TragicConflictEM)  # decorator-style
        return
    except Exception:
        pass

    try:
        from erisml.ethics.modules import EM_REGISTRY  # type: ignore

        EM_REGISTRY["tragic_conflict"] = TragicConflictEM  # mapping-style
    except Exception:
        # If neither is available, the EM can still be imported directly and instantiated.
        pass


_register()
